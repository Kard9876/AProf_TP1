{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T21:19:05.066702Z",
     "start_time": "2025-03-16T21:18:59.479360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries and classes\n",
    "\n",
    "\n",
    "# Common Imports\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from Code.utils.dataset import Dataset\n",
    "import Code.utils.store_model as store_model\n",
    "\n",
    "# DNN imports\n",
    "\n",
    "from Code.DNN.layers.sigmoid import SigmoidActivation\n",
    "from Code.DNN.functions.metrics import mse, accuracy\n",
    "from Code.DNN.networks.neuralnet import NeuralNetwork\n",
    "from Code.DNN.functions.mse import MeanSquaredError\n",
    "# from Code.DNN.layers.dense import DenseLayer\n",
    "from Code.DNN.layers.dropout import DropOutLayer\n",
    "from Code.DNN.optimizations.retained_gradient import RetGradient\n",
    "from Code.DNN.optimizations.l1_reg import L1Reg\n",
    "from Code.DNN.optimizations.l2_reg import L2Reg\n",
    "from Code.DNN.functions.bce import BinaryCrossEntropy\n",
    "\n",
    "\n",
    "# Logistic Regression imports\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from Code.LogisticRegression.logisticReg.logisticReg import LogisticRegression\n",
    "\n",
    "\n",
    "# RNN imports\n",
    "\n",
    "from Code.RNN.layers.sigmoid import SigmoidActivation\n",
    "from Code.RNN.functions.metrics import mse, accuracy\n",
    "from Code.RNN.networks.recorrent_neural_network import RecorrentNeuralNetwork\n",
    "from Code.RNN.functions.mse import MeanSquaredError\n",
    "from Code.RNN.layers.rnn import RNN\n",
    "from Code.RNN.layers.dense import DenseLayer\n",
    "from Code.RNN.optimizations.retained_gradient import RetGradient\n",
    "from Code.RNN.functions.bce import BinaryCrossEntropy\n",
    "from Code.RNN.layers.relu import ReLUActivation"
   ],
   "id": "853bb71df153f714",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mrjoa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T21:19:05.192450Z",
     "start_time": "2025-03-16T21:19:05.188936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seed to control randomness\n",
    "\n",
    "np.random.seed(42)"
   ],
   "id": "b57df8a90d99e714",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T21:19:12.509990Z",
     "start_time": "2025-03-16T21:19:05.438146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read datasets\n",
    "# Ignore if loading model from file\n",
    "\n",
    "dataset = Dataset('../Dataset/DatasetsGerados/dataset_training_input.csv',\n",
    "                      '../Dataset/DatasetsGerados/dataset_training_output.csv',\n",
    "                      '../Dataset/DatasetsGerados/dataset_validation_input.csv',\n",
    "                      '../Dataset/DatasetsGerados/dataset_validation_output.csv',\n",
    "                      '../Dataset/dataset2_inputs.csv',\n",
    "                      None)\n",
    "\n",
    "X_train, y_train, X_validation, y_validation, X_test, y_test, ids = dataset.get_dataset_embedding('Text', 'Label', sep='\\t', rem_punctuation=False)"
   ],
   "id": "9e8498de4f781178",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T21:20:15.473371Z",
     "start_time": "2025-03-16T21:19:12.578757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build model\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# network\n",
    "optimizer = RetGradient(learning_rate=0.001, momentum=0.90)\n",
    "loss = BinaryCrossEntropy()\n",
    "\n",
    "regulator = L2Reg(l2_val=0.01)\n",
    "model = RecorrentNeuralNetwork(epochs=10, batch_size=batch_size, optimizer=optimizer, regulator=regulator, verbose=True, loss=loss,\n",
    "                    metric=accuracy, patience=-1, min_delta=0.001)\n",
    "\n",
    "model.add(RNN(10, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(ReLUActivation())\n",
    "\n",
    "model.add(DenseLayer(1))\n",
    "model.add(SigmoidActivation())\n",
    "\n",
    "# Train network\n",
    "\n",
    "model.fit(X_train, y_train, X_val=X_validation, y_val=y_validation)\n",
    "\n",
    "# Plot learning curves\n",
    "\n",
    "model.plot_train_curves()"
   ],
   "id": "c065c8e451617348",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - loss: 5732.5180 - accuracy: 0.8540\n",
      "Epoch 2/10 - loss: 9350.2387 - accuracy: 0.8673\n",
      "Epoch 3/10 - loss: 18636.8414 - accuracy: 0.7767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrjoa\\Desktop\\Uni\\2 Semestre\\SI\\Apof\\Trabalho_1\\AProf_TP1\\Code\\RNN\\layers\\sigmoid.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-input))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - loss: 22665.6592 - accuracy: 0.7533\n",
      "Epoch 5/10 - loss: 17657.8700 - accuracy: 0.8007\n",
      "Epoch 6/10 - loss: 22555.5300 - accuracy: 0.7663\n",
      "Epoch 7/10 - loss: 18084.4018 - accuracy: 0.8117\n",
      "Epoch 8/10 - loss: 13231.1960 - accuracy: 0.8610\n",
      "Epoch 9/10 - loss: 15021.6551 - accuracy: 0.8430\n",
      "Epoch 10/10 - loss: 10623.7952 - accuracy: 0.8903\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T21:20:15.726157Z",
     "start_time": "2025-03-16T21:20:15.594779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test model\n",
    "\n",
    "# Predict test dataset\n",
    "\n",
    "out = model.predict(X_test)\n",
    "\n",
    "if y_test is not None:\n",
    "    print(model.score(y_test, out))\n",
    "\n",
    "# Store results\n",
    "\n",
    "results_filepath = './submissao1-grupo007-s2-v2.csv'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(results_filepath), exist_ok=True)\n",
    "\n",
    "results = dataset.merge_results(ids, out)\n",
    "results.to_csv(results_filepath, sep='\\t', index=False)"
   ],
   "id": "3a67e6fe57bd54dc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T21:20:15.965961Z",
     "start_time": "2025-03-16T21:20:15.745788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Store model and Dataset class\n",
    "\n",
    "dataset_filepath = './Model/dataset-s2'\n",
    "dataset_key = 'dataset-s2'\n",
    "\n",
    "store_model.store_model(dataset_filepath, dataset_key, dataset)\n",
    "\n",
    "# Store network model\n",
    "\n",
    "model_filepath = './Model/model-s2'\n",
    "model_key = 'model-s2'\n",
    "\n",
    "store_model.store_model(model_filepath, model_key, model)"
   ],
   "id": "8152ca3685965183",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T21:20:16.802341Z",
     "start_time": "2025-03-16T21:20:16.101285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve model and Dataset class\n",
    "\n",
    "# Retrieve Dataset class\n",
    "\n",
    "dataset_filepath = './Model/dataset-s2'\n",
    "dataset_key = 'dataset-s2'\n",
    "\n",
    "dataset = store_model.retrieve_model(dataset_filepath, dataset_key)\n",
    "\n",
    "# Retrieve model\n",
    "\n",
    "model_filepath = './Model/model-s2'\n",
    "model_key = 'model-s2'\n",
    "\n",
    "model = store_model.retrieve_model(model_filepath, model_key)\n",
    "\n",
    "# Load test dataset. If y_test doesn't exist, second parameter should be None\n",
    "\n",
    "dataset.set_dataset_test('../Dataset/dataset2_inputs.csv',\n",
    "                      None)\n",
    "\n",
    "X_test, y_test, ids = dataset.get_test_dataset_embedding('Text', 'Label', sep='\\t', rem_punctuation=False)"
   ],
   "id": "b30f9ceea12f2688",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
