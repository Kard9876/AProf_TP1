{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:56:04.027993Z",
     "start_time": "2025-03-30T14:55:58.559583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import needed libraries and classes\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.preprocessing as preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "\n",
    "from Code.utils.dataset import Dataset\n",
    "import Code.utils.store_model as store_model"
   ],
   "id": "853bb71df153f714",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mrjoa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:56:04.121009Z",
     "start_time": "2025-03-30T14:56:04.115009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#set seeds\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ],
   "id": "daad7fcbea1427dc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:56:04.328493Z",
     "start_time": "2025-03-30T14:56:04.318322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@register_keras_serializable()\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=self.num_heads, key_dim=self.embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(self.dense_dim, activation=\"relu\"),\n",
    "            layers.Dense(self.embed_dim),\n",
    "        ])\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n"
   ],
   "id": "7721f0f652bffe5a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:56:04.348603Z",
     "start_time": "2025-03-30T14:56:04.340613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@register_keras_serializable()\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=self.input_dim, output_dim=self.output_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=self.sequence_length, output_dim=self.output_dim\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config\n"
   ],
   "id": "e13f28308d0dcd6d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:56:04.473149Z",
     "start_time": "2025-03-30T14:56:04.359135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load datasets\n",
    "\n",
    "dataset = Dataset('../Dataset/DatasetsGerados/dataset_training_input.csv',\n",
    "                  '../Dataset/DatasetsGerados/dataset_training_output.csv',\n",
    "                  '../Dataset/DatasetsGerados/dataset_validation_input.csv',\n",
    "                  '../Dataset/DatasetsGerados/dataset_validation_output.csv',\n",
    "                  '../Dataset/dataset1_inputs.csv',\n",
    "                  None)\n",
    "\n",
    "X_train, y_train, X_validation, y_validation, X_test, y_test, ids = dataset.get_datasets_unprocessed('Text', 'Label', sep='\\t', rem_punctuation=True)"
   ],
   "id": "4dcead25fa1a37c1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:56:04.933189Z",
     "start_time": "2025-03-30T14:56:04.489829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#tokenization\n",
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)  # limit to top max_words words\n",
    "tokenizer.fit_on_texts(X_train.iloc[:, 0])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train.iloc[:, 0])\n",
    "X_validation = tokenizer.texts_to_sequences(X_validation.iloc[:, 0])\n",
    "X_test = tokenizer.texts_to_sequences(X_test.iloc[:, 0])\n",
    "\n",
    "X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_validation = preprocessing.sequence.pad_sequences(X_validation, maxlen=max_len)\n",
    "X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"
   ],
   "id": "9e8498de4f781178",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:04:18.435570Z",
     "start_time": "2025-03-30T14:56:04.949557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embed_dim = 128\n",
    "num_heads = 8\n",
    "dense_dim = 64\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(max_len, max_words, embed_dim)(inputs)\n",
    "\n",
    "for _ in range(1):\n",
    "    x = TransformerEncoder(\n",
    "        embed_dim,\n",
    "        dense_dim,\n",
    "        num_heads,\n",
    "    )(x)\n",
    "\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.8)(x)\n",
    "\n",
    "\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=0.01),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "model.summary()\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"full_transformer_encoder.keras\",\n",
    "                                    save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "    reduce_lr\n",
    "]\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_validation,y_validation), epochs=10, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"full_transformer_encoder.keras\", custom_objects={\"TransformerEncoder\": TransformerEncoder, \"PositionalEmbedding\": PositionalEmbedding})"
   ],
   "id": "c065c8e451617348",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mrjoa\\Desktop\\Uni\\2 Semestre\\SI\\Apof\\Aula 3\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_embedding            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │       \u001B[38;5;34m665,600\u001B[0m │\n",
       "│ (\u001B[38;5;33mPositionalEmbedding\u001B[0m)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │       \u001B[38;5;34m544,576\u001B[0m │\n",
       "│ (\u001B[38;5;33mTransformerEncoder\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalMaxPooling1D\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m129\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_embedding            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">665,600</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">544,576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,210,305\u001B[0m (4.62 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,210,305</span> (4.62 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,210,305\u001B[0m (4.62 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,210,305</span> (4.62 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m55s\u001B[0m 543ms/step - acc: 0.5222 - loss: 1.3035 - val_acc: 0.9570 - val_loss: 0.5854 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m52s\u001B[0m 558ms/step - acc: 0.7704 - loss: 0.4402 - val_acc: 0.9950 - val_loss: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 525ms/step - acc: 0.9978 - loss: 0.0135 - val_acc: 1.0000 - val_loss: 0.0029 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 523ms/step - acc: 1.0000 - loss: 0.0018 - val_acc: 1.0000 - val_loss: 0.0015 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m56s\u001B[0m 593ms/step - acc: 1.0000 - loss: 9.6838e-04 - val_acc: 1.0000 - val_loss: 7.7914e-04 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m59s\u001B[0m 623ms/step - acc: 1.0000 - loss: 6.6834e-04 - val_acc: 1.0000 - val_loss: 3.5133e-04 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m59s\u001B[0m 631ms/step - acc: 1.0000 - loss: 6.4057e-04 - val_acc: 1.0000 - val_loss: 7.8777e-04 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m58s\u001B[0m 618ms/step - acc: 1.0000 - loss: 3.6001e-04 - val_acc: 1.0000 - val_loss: 0.0010 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 521ms/step - acc: 1.0000 - loss: 4.6693e-04\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001B[1m94/94\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m54s\u001B[0m 569ms/step - acc: 1.0000 - loss: 4.6598e-04 - val_acc: 0.9990 - val_loss: 0.0012 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:04:19.737005Z",
     "start_time": "2025-03-30T15:04:18.511509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predict test dataset\n",
    "\n",
    "out = model.predict(X_test)\n",
    "\n",
    "if y_test is not None:\n",
    "    print(model.evaluate(X_test, y_test))\n",
    "\n",
    "# Store results\n",
    "\n",
    "results_filepath = './submissao3-grupo007-s2.csv'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(results_filepath), exist_ok=True)\n",
    "\n",
    "results = dataset.merge_results(ids, out)\n",
    "results.to_csv(results_filepath, sep='\\t', index=False)"
   ],
   "id": "3a67e6fe57bd54dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 177ms/step\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
